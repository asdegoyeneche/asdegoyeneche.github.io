<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="FGlDI9NR6oONjptUmHly9TxPgBTNJyOoN4rTd9i9RQA" />

<title>

  Alfredo  De Goyeneche


  | Publications

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">

<link rel="stylesheet" href="/~asdegoyeneche/assets/css/main.css">
<link rel="canonical" href="/~asdegoyeneche/publications">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/~asdegoyeneche/assets/js/theme.js"></script>
<script src="/~asdegoyeneche/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <!--  -->
      <a class="navbar-brand title font-weight-lighter" href="https://people.eecs.berkeley.edu/~asdegoyeneche/">
       <span class="font-weight-bold">Alfredo</span>   De Goyeneche
      </a>

      <!--  -->

      <div class="navbar-brand social">
          <a href="mailto:%61%73%64%65%67%6F%79%65%6E%65%63%68%65@%62%65%72%6B%65%6C%65%79.%65%64%75"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=76crpgsAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/asdegoyeneche" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/alfredo-de-goyeneche" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/adegoyeneche" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>










      </div>

      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- CV -->
          <li class="nav-item">
            <a class="nav-link" href="/~asdegoyeneche/assets/pdf/ResumeDeGoyeneche.pdf">
              CV
            </a>
          </li>         

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/~asdegoyeneche/">
              About
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/~asdegoyeneche/coursework">
                Coursework
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/~asdegoyeneche/publications">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/~asdegoyeneche/teaching">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description">* denotes equal contribution</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="wang2022high" class="col-sm-8"> -->
  <div id="wang2022high" class="col-sm-10">
    
      <div class="title">High Fidelity Deep Learning-based MRI Reconstruction with Instance-wise Discriminative Feature Matching Loss</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Wang, Ke,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tamir, Jonathan I,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wollner, Uri,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Brada, Rafi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yu, Stella,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lustig, Michael
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Magnetic Resonance in Medicine,</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.29227" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Purpose: To improve reconstruction fidelity of fine structures and textures in deep learning- (DL) based reconstructions. Methods: A novel patch-based Unsupervised Feature Loss (UFLoss) is proposed and incorporated into the training of DL-based reconstruction frameworks in order to preserve perceptual similarity and high-order statistics. The UFLoss provides instance-level discrimination by mapping similar instances to similar low-dimensional feature vectors and is trained without any human annotation. By adding an additional loss function on the low-dimensional feature space during training, the reconstruction frameworks from under-sampled or corrupted data can reproduce more realistic images that are closer to the original with finer textures, sharper edges, and improved overall image quality. The performance of the proposed UFLoss is demonstrated on unrolled networks for accelerated two- (2D) and three-dimensional (3D) knee MRI reconstruction with retrospective under-sampling. Quantitative metrics including normalized root mean squared error (NRMSE), structural similarity index (SSIM), and our proposed UFLoss were used to evaluate the performance of the proposed method and compare it with others. Results: In vivo experiments indicate that adding the UFLoss encourages sharper edges and more faithful contrasts compared to traditional and learning-based methods with pure  loss. More detailed textures can be seen in both 2D and 3D knee MR images. Quantitative results indicate that reconstruction with UFLoss can provide comparable NRMSE and a higher SSIM while achieving a much lower UFLoss value. Conclusion: We present UFLoss, a patch-based unsupervised learned feature loss, which allows the training of DL-based reconstruction to obtain more detailed texture, finer features, and sharper edges with higher overall image quality under DL-based reconstruction frameworks. (Code available at: https://github.com/mikgroup/UFLoss)</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="degoyeneche2022resonet" class="col-sm-8"> -->
  <div id="degoyeneche2022resonet" class="col-sm-10">
    
      <div class="title">ResoNet: Physics Informed Deep Learning based Off-Resonance Correction Trained on Synthetic Data</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ramachandran, Shreya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wang, Ke,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Karasan, Ekin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yu, Stella,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lustig, Michael
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 31st Annual Meeting of ISMRM,</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://index.mirasmart.com/ISMRM2022/PDFfiles/0555.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose a physics-inspired, unrolled-deep-learning framework for off-resonance correction. Our forward model includes coil sensitivities, multi-frequency bins, and non-uniform Fourier transforms hence compatible with fat/water imaging and parallel imaging acceleration. The network, which includes data-consistency terms and CNN modules serving as proximal operators, is trained end-to-end using only synthetic random field maps, coil sensitivities, and noise-like images with statistics (smoothness) mimicking natural signals. Our aim is to train the network to reverse off-resonance irrespective of the type of imaging, and hence generalizable to any anatomy and contrast without retraining. We demonstrate initial results in simulations, phantom, and in-vivo data.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="wang2022rigorous" class="col-sm-8"> -->
  <div id="wang2022rigorous" class="col-sm-10">
    
      <div class="title">Rigorous Uncertainty Estimation for MRI Reconstruction</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Wang, Ke,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Angelopoulos, Anastasios,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kohli, Amit,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shimron, Efrat,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yu, Stella X,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Malik, Jitendra,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lustig, Michael
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 31st Annual Meeting of ISMRM,</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://index.mirasmart.com/ISMRM2022/PDFfiles/0749.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep-learning (DL)-based MRI reconstructions have shown great potential to reduce scan time while maintaining diagnostic image quality. However, their adoption has been plagued with fears that the models will hallucinate or eliminate important anatomical features. To address this issue, we develop a framework to identify when and where a reconstruction model is producing potentially misleading results. Specifically, our framework produces confidence intervals at each pixel of a reconstruction image such that 95% of these intervals contain the true pixel value with high probability. In-vivo 2D knee and brain reconstruction results demonstrate the effectiveness of our proposed uncertainty estimation framework.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="shimron2022bladenet" class="col-sm-8"> -->
  <div id="shimron2022bladenet" class="col-sm-10">
    
      <div class="title">BladeNet: Rapid PROPELLER Acquisition and Reconstruction for High spatio-temporal Resolution Abdominal MRI</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Shimron, Efrat,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wang, Ke,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Syed, Ali Bin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vasanawala, Shreyas,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lustig, Michael
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 31st Annual Meeting of ISMRM,</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://index.mirasmart.com/ISMRM2022/PDFfiles/0684.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>To improve bowel wall imaging in abdominal pediatric MRI scans, we propose a multi-phase single-shot fast spin echo (SSFSE) PROPELLER acquisition with novel deep learning reconstruction. This acquisition offers shorter scan time and thus higher temporal resolution, PROPELLER built-in motion correction, and alias-free images; these however exhibit spatial blurring. Our approach leverages the blurring-axis temporal rotation and data redundancy; we train a network to recover high-frequency spatial details from consecutive frames. Retrospective simulations with data from balanced SSFP scans show that this approach yields reconstructions with high spatio-temporal resolution and motion-correction, which are essential for pediatric abdominal imaging.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="degoyeneche2021deep" class="col-sm-8"> -->
  <div id="degoyeneche2021deep" class="col-sm-10">
    
      <div class="title">Deep-Learning-Based Motion Correction For Quantitative Cardiac MRI</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tang, Shuyu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Addy, Nii Okai,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hu, Bob S,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Overall, William,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Santos, Juan M
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 29th Annual Meeting of ISMRM,</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.ismrm.org/21/program-files/O-46.htm" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We developed a deep-learning-based approach for motion correction in quantitative cardiac MRI, including perfusion, T1 mapping, and T2 mapping. The proposed approach consists of a segmentation network and a registration network. The segmentation network was trained using 2D short-axis images for each of the three sequences, while the same registration network was shared between all three sequences. The proposed approach was faster and more accurate than a popular traditional registration method. Our work is beneficial for building a faster and more robust automated processing pipeline to obtain CMR parametric maps.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="riquelme2020explaining" class="col-sm-8"> -->
  <div id="riquelme2020explaining" class="col-sm-10">
    
      <div class="title">Explaining VQA predictions using visual grounding and a knowledge base</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Riquelme, Felipe*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo*</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhang, Yundong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Niebles, Juan Carlos,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Soto, Alvaro
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Image and Vision Computing,</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S0262885620301001" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this work, we focus on the Visual Question Answering (VQA) task, where a model must answer a question based on an image, and the VQA-Explanations task, where an explanation is produced to support the answer. We introduce an interpretable model capable of pointing out and consuming information from a novel Knowledge Base (KB) composed of real-world relationships between objects, along with labels mined from available region descriptions and object annotations. Furthermore, this model provides a visual and textual explanations to complement the KB visualization. The use of a KB brings two important consequences: enhance predictions and improve interpretability. We achieve this by introducing a mechanism that can extract relevant information from this KB, and can point out the relations better suited for predicting the answer. A supervised attention map is generated over the KB to select the relevant relationships from it for each question-image pair. Moreover, we add image attention supervision on the explanations module to generate better visual and textual explanations. We quantitatively show that the predicted answers improve when using the KB; similarly, explanations improve with this and when adding image attention supervision. Also, we qualitatively show that the KB attention helps to improve interpretability and enhance explanations. Overall, the results support the benefits of having multiple tasks to enhance the interpretability and performance of the model.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="degoyeneche2019rapid" class="col-sm-8"> -->
  <div id="degoyeneche2019rapid" class="col-sm-10">
    
      <div class="title">Rapid Automated Cardiac Imaging</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Addy, Nii Okai,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Islam, Haisam,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Peterson, Eric,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Overall, William,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Santos, Juan M,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Hu, Bob S
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Frontier of AI-Assisted Care (FAC) Scientific Symposium,</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://med.stanford.edu/frontierofaicare/abstracts.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="degoyeneche2019one" class="col-sm-8"> -->
  <div id="degoyeneche2019one" class="col-sm-10">
    
      <div class="title">One-Click Spine MRI</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Peterson, Eric,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  He, J Jason,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Addy, N Okai,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Santos, Juan M
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Medical Imaging Meets NeurIPS Workshop at NeurIPS,</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://sites.google.com/view/med-neurips-2019/Abstracts" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
<!--   <div class="col-sm-2 abbr">
  
  </div> -->

  <!-- <div id="degoyeneche2019automated" class="col-sm-8"> -->
  <div id="degoyeneche2019automated" class="col-sm-10">
    
      <div class="title">Automated Cardiac Magnetic Resonance Imaging</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>De Goyeneche, Alfredo</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Addy, Nii O,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Santos, Juan M,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Hu, Bob S
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Circulation,</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.ahajournals.org/doi/abs/10.1161/circ.140.suppl_1.17153" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Introduction: Access, affordability, and accuracy of MRI examinations can all be vastly improved with machine learning-assisted automated imaging. We show that cardiac function can be clinically acquired and analyzed in less than 3 minutes or entire cardiac stress studies in less than 15 minutes with an automated workflow. Methods: We developed a flexible software architecture for image acquisition, recognition, and control. Human operator tasks including image recognition, planning, adjustments, and analysis are replaced by neural networks. The network was trained using TensorFlow with data from 58 clinical exams. The trained network sequentially located the complete set of standard views, in real time (Fig 1). A separate U-Net based model was trained to automatically segment the LV mass and volume for ejection fraction and cardiac mass. For the 15 minute scan, the desired inversion time was automatically determined using neural network outputs. Finally, a neural network was trained to detect image artifacts and repeat scans in the case of insufficient image quality. Results: In-vivo imaging was performed on a 1.5 T GE Signa scanner. Real-time spiral imaging was performed at 114 ms temporal resolution, reconstructed at 30 frames per second and 15 inferences per second. During inference, the network continuously analyzed series of real-time frames until a stable prescription was determined to minimize the effects of cardiac and respiratory motion. In a feasibility test of 50 patients, the network successfully found all standard views and segmented both ventricles without operator intervention. All scans, reconstructions, and analyses were completed in under 3 minutes. Conclusion: AI-assisted cardiac MRI examinations can be acquired rapidly with high precision which could profoundly affect the affordability, accessibility, and accuracy of cardiac diagnoses.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Alfredo  De Goyeneche.
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/~asdegoyeneche/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/~asdegoyeneche/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/~asdegoyeneche/assets/js/common.js"></script>


</html>
